<<<<<<< HEAD
Course Q&A Chatbot
An intelligent question-answering system that processes course materials and provides accurate, context-aware answers using advanced AI and vector search technologies.
ðŸš€ Features
â€¢	Multi-format Document Support: Upload and process PDF, DOCX, CSV, and TXT files
â€¢	Intelligent Text Processing: Smart chunking that preserves document structure and context
â€¢	Advanced Search: Hybrid retrieval combining semantic search and keyword matching
â€¢	AI-Powered Answers: Google Gemini integration for comprehensive, contextual responses
â€¢	Spelling Variation Tolerance: Automatically handles typos and word variations
â€¢	Citation System: Source tracking with confidence scores and references
â€¢	RESTful API: FastAPI-based with comprehensive endpoints and CORS support
ðŸ“¦ Installation
Prerequisites
â€¢	Python 3.8+
â€¢	MongoDB
â€¢	Pinecone account
â€¢	Google AI Studio API key
Quick Start
1.	Clone and setup
bash
git clone <repository-url>
cd course-qa-chatbot
2.	Install dependencies
bash
pip install -r requirements.txt
3.	Environment Configuration
Create a .env file:
env
=======
# Course Q&A Chatbot

An AI-powered chatbot that answers course-related questions by processing uploaded documents and using vector search with Google Gemini.

---

## ðŸš€ Features
- Upload PDF, DOCX, CSV, TXT files
- Smart text chunking and context-aware search
- AI-powered answers with Google Gemini
- REST API built with FastAPI
- MongoDB + Pinecone for storage and vector search

---

## ðŸ“¦ Installation

### Requirements
- Python 3.8+
- MongoDB
- Pinecone API Key
- Google AI Studio API Key

### Setup
```bash
git clone <repository-url>
cd course-qa-chatbot
pip install -r requirements.txt
Create a .env file:

env
Copy code
>>>>>>> e6bf5b677035b37fc2272f718d3a857950be0fdf
MONGO_URI=mongodb://localhost:27017
MONGO_DB=courseqa
PINECONE_API_KEY=your_pinecone_key
GOOGLE_API_KEY=your_gemini_key
PORT=8000
<<<<<<< HEAD
4.	Start the application
bash
python main.py
ðŸš€ Usage
Upload Documents
bash
curl -X POST -F "file=@course_materials.pdf" http://localhost:8000/api/v1/upload
Ask Questions
bash
curl "http://localhost:8000/api/v1/answer?query=explain%20machine%20learning"
API Endpoints
Method	Endpoint	Description
POST	/api/v1/upload	Upload documents
GET	/api/v1/answer	Get answers
GET	/api/v1/documents/count	Document count
DELETE	/api/v1/documents	Clear documents
GET	/health	Health check
ðŸ”§ Configuration
Environment Variables
Variable	Description	Default
MONGO_URI	MongoDB connection	mongodb://localhost:27017
PINECONE_API_KEY	Pinecone API key	Required
GOOGLE_API_KEY	Gemini AI API key	Required
PORT	Server port	8000
Model Configuration
â€¢	Embedding Model: all-MiniLM-L6-v2
â€¢	Reranking Model: cross-encoder/ms-marco-MiniLM-L-6-v2
â€¢	LLM: Google Gemini 2.0 Flash
ðŸ› ï¸ Development
Project Structure
text
backend/
â”œâ”€â”€ main.py              # FastAPI application
â”œâ”€â”€ core/               # Configuration & database
â”œâ”€â”€ models/             # Data schemas
â”œâ”€â”€ api/               # Route handlers
â”œâ”€â”€ services/          # Business logic
â””â”€â”€ utils/             # Utilities & helpers
Key Components
Intelligent Chunking
â€¢	Preserves document sections and headings
â€¢	Maintains sentence boundaries
â€¢	Configurable chunk sizes with overlap
Hybrid Retrieval
â€¢	Semantic search with vector similarity
â€¢	Keyword search with regex matching
â€¢	Automatic spelling correction
â€¢	Cross-encoder re-ranking
Spelling Tolerance
Handles variations like:
â€¢	Plurals (internship â†’ internships)
â€¢	Common typos (navigations â†’ navigation)
â€¢	Verb forms (developing â†’ development)
ðŸ“Š Performance
â€¢	File Size: 50MB maximum per upload
â€¢	Response Time: 1-4 seconds typical
â€¢	Document Formats: PDF, DOCX, CSV, TXT, MD
ðŸ” Troubleshooting
Common Issues
No results for valid queries
â€¢	Verify documents are uploaded
â€¢	Check MongoDB connection
â€¢	Ensure Pinecone index exists
Spelling variations not working
â€¢	Check spellchecker installation
â€¢	Review search strategy logs
Slow response times
â€¢	Optimize chunk sizes
â€¢	Check model loading times
Logs and Monitoring
Enable debug logging:
python
logging.basicConfig(level=logging.DEBUG)
ðŸš€ Deployment
Production Setup
bash
uvicorn main:app --host 0.0.0.0 --port 8000 --workers 4
ðŸ“„ License
MIT License - see LICENSE file for details.
ðŸ™ Acknowledgments
â€¢	Google Gemini AI for language understanding
â€¢	Sentence Transformers for embeddings
â€¢	Pinecone for vector search
â€¢	FastAPI for high-performance API
=======
Run the app:

bash
Copy code
python main.py
ðŸ“– Usage
Upload a document:

bash
Copy code
curl -X POST -F "file=@notes.pdf" http://localhost:8000/api/v1/upload
Ask a question:

bash
Copy code
curl "http://localhost:8000/api/v1/answer?query=what%20is%20machine%20learning"
ðŸ”§ API Endpoints
POST /api/v1/upload â†’ Upload documents

GET /api/v1/answer â†’ Get answers

GET /api/v1/documents/count â†’ Count uploaded docs

DELETE /api/v1/documents â†’ Clear documents

GET /health â†’ Health check
>>>>>>> e6bf5b677035b37fc2272f718d3a857950be0fdf

