Course Q&A Chatbot
An intelligent question-answering system that processes course materials and provides accurate, context-aware answers using advanced AI and vector search technologies.
ğŸš€ Features
â€¢	Multi-format Document Support: Upload and process PDF, DOCX, CSV, and TXT files
â€¢	Intelligent Text Processing: Smart chunking that preserves document structure and context
â€¢	Advanced Search: Hybrid retrieval combining semantic search and keyword matching
â€¢	AI-Powered Answers: Google Gemini integration for comprehensive, contextual responses
â€¢	Spelling Variation Tolerance: Automatically handles typos and word variations
â€¢	Citation System: Source tracking with confidence scores and references
â€¢	RESTful API: FastAPI-based with comprehensive endpoints and CORS support
ğŸ“¦ Installation
Prerequisites
â€¢	Python 3.8+
â€¢	MongoDB
â€¢	Pinecone account
â€¢	Google AI Studio API key
Quick Start
1.	Clone and setup
bash
git clone <repository-url>
cd course-qa-chatbot
2.	Install dependencies
bash
pip install -r requirements.txt
3.	Environment Configuration
Create a .env file:
env
MONGO_URI=mongodb://localhost:27017
MONGO_DB=courseqa
PINECONE_API_KEY=your_pinecone_key
GOOGLE_API_KEY=your_gemini_key
PORT=8000
4.	Start the application
bash
python main.py
ğŸš€ Usage
Upload Documents
bash
curl -X POST -F "file=@course_materials.pdf" http://localhost:8000/api/v1/upload
Ask Questions
bash
curl "http://localhost:8000/api/v1/answer?query=explain%20machine%20learning"
API Endpoints
Method	Endpoint	Description
POST	/api/v1/upload	Upload documents
GET	/api/v1/answer	Get answers
GET	/api/v1/documents/count	Document count
DELETE	/api/v1/documents	Clear documents
GET	/health	Health check
ğŸ”§ Configuration
Environment Variables
Variable	Description	Default
MONGO_URI	MongoDB connection	mongodb://localhost:27017
PINECONE_API_KEY	Pinecone API key	Required
GOOGLE_API_KEY	Gemini AI API key	Required
PORT	Server port	8000
Model Configuration
â€¢	Embedding Model: all-MiniLM-L6-v2
â€¢	Reranking Model: cross-encoder/ms-marco-MiniLM-L-6-v2
â€¢	LLM: Google Gemini 2.0 Flash
ğŸ› ï¸ Development
Project Structure
text
backend/
â”œâ”€â”€ main.py              # FastAPI application
â”œâ”€â”€ core/               # Configuration & database
â”œâ”€â”€ models/             # Data schemas
â”œâ”€â”€ api/               # Route handlers
â”œâ”€â”€ services/          # Business logic
â””â”€â”€ utils/             # Utilities & helpers
Key Components
Intelligent Chunking
â€¢	Preserves document sections and headings
â€¢	Maintains sentence boundaries
â€¢	Configurable chunk sizes with overlap
Hybrid Retrieval
â€¢	Semantic search with vector similarity
â€¢	Keyword search with regex matching
â€¢	Automatic spelling correction
â€¢	Cross-encoder re-ranking
Spelling Tolerance
Handles variations like:
â€¢	Plurals (internship â†’ internships)
â€¢	Common typos (navigations â†’ navigation)
â€¢	Verb forms (developing â†’ development)
ğŸ“Š Performance
â€¢	File Size: 50MB maximum per upload
â€¢	Response Time: 1-4 seconds typical
â€¢	Document Formats: PDF, DOCX, CSV, TXT, MD
ğŸ” Troubleshooting
Common Issues
No results for valid queries
â€¢	Verify documents are uploaded
â€¢	Check MongoDB connection
â€¢	Ensure Pinecone index exists
Spelling variations not working
â€¢	Check spellchecker installation
â€¢	Review search strategy logs
Slow response times
â€¢	Optimize chunk sizes
â€¢	Check model loading times
Logs and Monitoring
Enable debug logging:
python
logging.basicConfig(level=logging.DEBUG)
ğŸš€ Deployment
Production Setup
bash
uvicorn main:app --host 0.0.0.0 --port 8000 --workers 4
ğŸ“„ License
MIT License - see LICENSE file for details.
ğŸ™ Acknowledgments
â€¢	Google Gemini AI for language understanding
â€¢	Sentence Transformers for embeddings
â€¢	Pinecone for vector search
â€¢	FastAPI for high-performance API

